name: CI Bootstrap (Stub)

on:
  workflow_dispatch:
    inputs:
      env:
        description: "Environment to target (dev/test/staging/prod)"
        required: true
        default: "dev"
      region:
        description: "AWS region"
        required: true
        default: "eu-west-2"
      cluster_name:
        description: "EKS cluster name"
        required: false
        default: ""
      build_id:
        description: "Build ID for ephemeral runs"
        required: false
        default: ""
      lifecycle:
        description: "Lifecycle (ephemeral or persistent)"
        required: true
        default: "ephemeral"

jobs:
  bootstrap:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      ENV: ${{ inputs.env }}
      AWS_REGION: ${{ inputs.region }}
      CLUSTER_NAME: ${{ inputs.cluster_name }}
      BUILD_ID: ${{ inputs.build_id }}
      CLUSTER_LIFECYCLE: ${{ inputs.lifecycle }}
      TF_DIR: envs/${{ inputs.env }}
      LB_CLEANUP_ATTEMPTS: "5"
      LB_CLEANUP_INTERVAL: "20"
      REMOVE_K8S_SA_FROM_STATE: "true"
      ENABLE_TF_K8S_RESOURCES: "true"
      TF_AUTO_APPROVE: "true"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      # Phase 1: Preflight + tooling
      # Goal: ensure CLI tools are available and inputs are valid before any changes.
      - name: Phase 1 - Preflight checks (stub)
        run: |
          echo "Phase 1: validate inputs and tools"
          echo "ENV=${ENV}"
          echo "AWS_REGION=${AWS_REGION}"
          echo "CLUSTER_LIFECYCLE=${CLUSTER_LIFECYCLE}"
          echo "BUILD_ID=${BUILD_ID}"

      - name: Resolve cluster name
        run: |
          if [[ -z "${CLUSTER_NAME}" ]]; then
            CLUSTER_NAME="$(ENV=${ENV} TF_DIR=${TF_DIR} BUILD_ID=${BUILD_ID} CLUSTER_LIFECYCLE=${CLUSTER_LIFECYCLE} bash scripts/resolve-cluster-name.sh)"
          fi
          echo "CLUSTER_NAME=${CLUSTER_NAME}" >> "${GITHUB_ENV}"
          echo "Resolved CLUSTER_NAME=${CLUSTER_NAME}"

      # Timing note (baseline, non-blocking)
      - name: Timing log (stub)
        run: |
          echo "CI timing log"
          echo "Start: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          echo "End:   $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          echo "Capture timestamps around real apply/bootstrap steps once wired."

      # Phase 2: Terraform init/plan/apply
      # Goal: provision or update infra deterministically.
      - name: Phase 2 - Terraform (stub)
        run: |
          TF_VAR_cluster_lifecycle="${CLUSTER_LIFECYCLE}" \
          TF_VAR_build_id="${BUILD_ID}" \
          TF_VAR_owner_team="platform-team" \
          make apply ENV="${ENV}" BUILD_ID="${BUILD_ID}"

      # Phase 3: Bootstrap runner
      # Goal: install core platform tooling in the enforced order.
      - name: Phase 3 - Bootstrap runner (stub)
        run: |
          ENV_NAME="${ENV}" \
          NODE_INSTANCE_TYPE="t3.small" \
          SKIP_ARGO_SYNC_WAIT="true" \
          SKIP_CERT_MANAGER_VALIDATION="true" \
          COMPACT_OUTPUT="false" \
          ENABLE_TF_K8S_RESOURCES="${ENABLE_TF_K8S_RESOURCES}" \
          SCALE_DOWN_AFTER_BOOTSTRAP="false" \
          TF_DIR="${TF_DIR}" \
          CLUSTER="${CLUSTER_NAME}" \
          REGION="${AWS_REGION}" \
          make bootstrap ENV="${ENV}" BUILD_ID="${BUILD_ID}"

      # Phase 4: Post-bootstrap validation
      # Goal: capture a deterministic status summary for CI logs.
      - name: Phase 4 - Post-bootstrap checks (stub)
        run: |
          echo "Phase 4: sanity checks and Argo status summary go here"
          echo "kubectl get nodes"
          echo "kubectl -n argocd get applications"

      # Phase 5: Optional teardown (ephemeral only)
      # Goal: tear down safely when requested or scheduled.
      - name: Phase 5 - Teardown (stub)
        if: ${{ inputs.lifecycle == 'ephemeral' }}
        run: |
          TEARDOWN_CONFIRM="true" \
          RELAX_PDB="true" \
          DRAIN_TIMEOUT="300s" \
          HEARTBEAT_INTERVAL="30" \
          TF_DIR="${TF_DIR}" \
          CLUSTER="${CLUSTER_NAME}" \
          REGION="${AWS_REGION}" \
          make teardown ENV="${ENV}" BUILD_ID="${BUILD_ID}"
