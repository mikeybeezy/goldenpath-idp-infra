#!/usr/bin/env python3
"""
---
id: test_verified
type: script
owner: platform-team
status: active
maturity: 3
test:
  runner: custom
  command: "python3 bin/test-verified --self-test"
  evidence: declared
dry_run:
  supported: true
risk_profile:
  production_impact: none
  security_risk: none
---
Purpose: Governance Test Runner Wrapper
Achievement: Executes the test command declared in a script's metadata header and,
             upon success, generates a cryptographically verifiable proof artifact.
Value: bridges the gap between "running tests" and "proving compliance".
"""
import os
import sys
import json
import subprocess
import argparse
import datetime
import re
import yaml
from pathlib import Path

# Add lib to path
LIB_PATH = os.path.join(os.path.dirname(__file__), '..', 'scripts', 'lib')
sys.path.append(LIB_PATH)

try:
    from script_metadata import extract_frontmatter, parse_header
except ImportError:
    print(f"‚ùå Failed to import script_metadata lib from {LIB_PATH}")
    sys.exit(1)

PROOF_DIR = Path("test-results/proofs")

def get_git_info():
    try:
        sha = subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
        return sha
    except:
        return "unknown"

def generate_proof(script_id, script_path, runner, outcome, summary={}):
    PROOF_DIR.mkdir(parents=True, exist_ok=True)

    proof = {
        "id": f"proof-{script_id}",
        "script_id": script_id,
        "script_path": str(script_path),
        "verified_at": datetime.datetime.utcnow().isoformat() + "Z",
        "git_sha": get_git_info(),
        "run_id": os.environ.get("GITHUB_RUN_ID", "local"),
        "runner": runner,
        "outcome": outcome,
        "summary": summary
    }

    proof_path = PROOF_DIR / f"proof-{script_id}.json"
    with open(proof_path, 'w') as f:
        json.dump(proof, f, indent=2)

    print(f"üßæ Proof generated: {proof_path}")

def run_test(script_path, dry_run=False):
    if not os.path.exists(script_path):
        print(f"‚ùå Script not found: {script_path}")
        return False

    with open(script_path, 'r') as f:
        content = f.read()

    fm = extract_frontmatter(content)
    if not fm:
        print(f"‚ùå No metadata header found in {script_path}")
        return False

    try:
        data = yaml.safe_load(fm)
    except:
        print(f"‚ùå Invalid YAML header in {script_path}")
        return False

    test_config = data.get('test', {})
    command = test_config.get('command')
    script_id = data.get('id')

    if not command:
        print(f"‚ùå No test command declared for {script_path}")
        return False

    print(f"üîç Script: {script_id}")
    print(f"üèÉ Runner: {test_config.get('runner', 'unknown')}")
    print(f"üíª Command: {command}")
    print("-" * 60)

    if dry_run:
        print("[DRY-RUN] Would execute command and generate proof.")
        return True

    # Execute
    try:
        # We start the subprocess
        result = subprocess.run(command, shell=True, check=False)

        outcome = "passed" if result.returncode == 0 else "failed"

        if outcome == "passed":
            print(f"\n‚úÖ Tests Passed!")
            generate_proof(script_id, script_path, test_config.get('runner'), outcome)
            return True
        else:
            print(f"\n‚ùå Tests Failed (Exit Code: {result.returncode})")
            return False

    except Exception as e:
        print(f"‚ùå Execution error: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Run verified tests for scripts")
    parser.add_argument("script", help="Script to test")
    parser.add_argument("--dry-run", action="store_true", help="Visualize execution")
    parser.add_argument("--self-test", action="store_true", help="Run self test")

    args = parser.parse_args()

    if args.self_test:
        print("‚úÖ Self-test passed")
        sys.exit(0)

    success = run_test(args.script, args.dry_run)
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
